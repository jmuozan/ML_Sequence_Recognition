{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install libraries\n",
    "!pip install mediapipe opencv-python pandas scikit-learn numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediapipe initialization and Video recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Check that the camera and mediapipe are working\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose, \\\n",
    "        mp.solutions.hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            ret, image = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Unable to read frame from video capture\")\n",
    "                break\n",
    "\n",
    "            # Flip image to simulate mirror view\n",
    "            image = cv2.flip(image, 1)\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make detections\n",
    "            pose_results = pose.process(image)\n",
    "            hand_results = hands.process(image)\n",
    "\n",
    "            # RGB 2 BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Draw points\n",
    "            if pose_results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    pose_results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2),\n",
    "                )\n",
    "\n",
    "            if hand_results.multi_hand_landmarks:\n",
    "                for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image,\n",
    "                        hand_landmarks,\n",
    "                        mp.solutions.hands.HAND_CONNECTIONS,\n",
    "                        mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                        mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2),\n",
    "                    )\n",
    "\n",
    "            cv2.imshow(\"Raw Webcam Feed\", image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Record video for data capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30 \n",
    "    print(f\"Video Resolution: {width}x{height} at {fps} FPS\")\n",
    "\n",
    "    # Define the codec\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID') \n",
    "    out = cv2.VideoWriter('output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Error: Unable to read frame from video capture\")\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_rgb.flags.writeable = False\n",
    "        results = hands.process(frame_rgb)  \n",
    "        frame_rgb.flags.writeable = True\n",
    "        frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Write every frame\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('MediaPipe Hands', frame)  \n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'): \n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Create CSV to store data\n",
    "headers = ['class', 'accuracy', 'sequence'] \n",
    "headers.extend([f'pose_{coord}{i}' for i in range(33) for coord in ('x', 'y', 'z', 'v')])\n",
    "headers.extend([f'{hand}_{coord}{i}' for hand in ('right_hand', 'left_hand') for i in range(21) for coord in ('x', 'y', 'z', 'v')])\n",
    "\n",
    "with open('coordinates_1.csv', mode='w', newline='') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerow(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Capture data for different 'movements'\n",
    "cap = cv2.VideoCapture('_.mp4')\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('processed_output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    pose_drawing_spec = mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4)\n",
    "    hand_drawing_spec = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
    "\n",
    "    record = False\n",
    "    accuracy = None\n",
    "    sequences = {'r': -1, 'w': -1}  # Separate counters for 'r' and 'w'\n",
    "    recording_state = None\n",
    "\n",
    "    with open('coordinates_1.csv', mode='a', newline='') as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print(\"Error: Unable to read frame from video capture\")\n",
    "                break\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_rgb.flags.writeable = False\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "            hand_results = hands.process(frame_rgb)\n",
    "            frame_rgb.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if pose_results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    pose_results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=pose_drawing_spec,\n",
    "                    connection_drawing_spec=pose_drawing_spec)\n",
    "\n",
    "            if hand_results.multi_hand_landmarks:\n",
    "                for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame,\n",
    "                        hand_landmarks,\n",
    "                        mp_hands.HAND_CONNECTIONS,\n",
    "                        landmark_drawing_spec=hand_drawing_spec,\n",
    "                        connection_drawing_spec=hand_drawing_spec)\n",
    "\n",
    "            # Select the sequence number based on the key pressed\n",
    "            current_sequence = sequences[recording_state] if recording_state else -1\n",
    "            row = ['', accuracy, current_sequence]\n",
    "\n",
    "            if pose_results.pose_landmarks:\n",
    "                for lm in pose_results.pose_landmarks.landmark:\n",
    "                    visibility_binary = 1 if lm.visibility > 0.3 else 0\n",
    "                    row.extend([lm.x, lm.y, lm.z, visibility_binary])\n",
    "            else:\n",
    "                row.extend([0] * 33 * 4)\n",
    "\n",
    "            for hand in ('right_hand', 'left_hand'):\n",
    "                found = False\n",
    "                if hand_results.multi_hand_landmarks:\n",
    "                    for hand_landmarks, handedness in zip(hand_results.multi_hand_landmarks, hand_results.multi_handedness):\n",
    "                        if handedness.classification[0].label == ('Right' if hand == 'right_hand' else 'Left'):\n",
    "                            for lm in hand_landmarks.landmark:\n",
    "                                visibility_binary = 1 if lm.visibility > 0.2 else 0\n",
    "                                row.extend([lm.x, lm.y, lm.z, visibility_binary])\n",
    "                            found = True\n",
    "                            break\n",
    "                if not found:\n",
    "                    row.extend([0] * 21 * 4)\n",
    "\n",
    "            if record:\n",
    "                csv_writer.writerow(row)\n",
    "\n",
    "            out.write(frame)\n",
    "            cv2.imshow('MediaPipe Pose', frame)\n",
    "            key = cv2.waitKey(5) & 0xFF\n",
    "\n",
    "            if key == ord('r') or key == ord('w'):\n",
    "                new_state = chr(key)\n",
    "                if new_state != recording_state:\n",
    "                    sequences[new_state] += 1  # Update the specific sequence counter\n",
    "                    recording_state = new_state\n",
    "                record = True\n",
    "                accuracy = 1 if key == ord('r') else 0\n",
    "            elif key == ord('s'):\n",
    "                record = False\n",
    "                recording_state = None\n",
    "            elif key == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "df = pd.read_csv('coordinates_1.csv')\n",
    "df.loc[df['accuracy'].notna(), 'class'] = 'movement_1'\n",
    "df.to_csv('coordinates_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Capture data for different 'movements' and output to a new CSV without headers\n",
    "cap = cv2.VideoCapture('_.mp4')\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('processed_output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    pose_drawing_spec = mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4)\n",
    "    hand_drawing_spec = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
    "\n",
    "    record = False\n",
    "    accuracy = None\n",
    "    sequences = {'r': -1, 'w': -1}  # Separate counters for 'r' and 'w'\n",
    "    recording_state = None\n",
    "\n",
    "    with open('coordinates_2.csv', mode='a', newline='') as file:\n",
    "        csv_writer = csv.writer(file, lineterminator='\\n')\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print(\"Error: Unable to read frame from video capture\")\n",
    "                break\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_rgb.flags.writeable = False\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "            hand_results = hands.process(frame_rgb)\n",
    "            frame_rgb.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if pose_results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    pose_results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=pose_drawing_spec,\n",
    "                    connection_drawing_spec=pose_drawing_spec)\n",
    "\n",
    "            if hand_results.multi_hand_landmarks:\n",
    "                for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame,\n",
    "                        hand_landmarks,\n",
    "                        mp_hands.HAND_CONNECTIONS,\n",
    "                        landmark_drawing_spec=hand_drawing_spec,\n",
    "                        connection_drawing_spec=hand_drawing_spec)\n",
    "\n",
    "            current_sequence = sequences[recording_state] if recording_state else -1\n",
    "            row = ['', accuracy, current_sequence]\n",
    "\n",
    "            if pose_results.pose_landmarks:\n",
    "                for lm in pose_results.pose_landmarks.landmark:\n",
    "                    visibility_binary = 1 if lm.visibility > 0.3 else 0\n",
    "                    row.extend([lm.x, lm.y, lm.z, visibility_binary])\n",
    "            else:\n",
    "                row.extend([0] * 33 * 4)\n",
    "\n",
    "            for hand in ('right_hand', 'left_hand'):\n",
    "                found = False\n",
    "                if hand_results.multi_hand_landmarks:\n",
    "                    for hand_landmarks, handedness in zip(hand_results.multi_hand_landmarks, hand_results.multi_handedness):\n",
    "                        if handedness.classification[0].label == ('Right' if hand == 'right_hand' else 'Left'):\n",
    "                            for lm in hand_landmarks.landmark:\n",
    "                                visibility_binary = 1 if lm.visibility > 0.2 else 0\n",
    "                                row.extend([lm.x, lm.y, lm.z, visibility_binary])\n",
    "                            found = True\n",
    "                            break\n",
    "                if not found:\n",
    "                    row.extend([0] * 21 * 4)\n",
    "\n",
    "            if record:\n",
    "                csv_writer.writerow(row)\n",
    "\n",
    "            out.write(frame)\n",
    "            cv2.imshow('MediaPipe Pose', frame)\n",
    "            key = cv2.waitKey(5) & 0xFF\n",
    "\n",
    "            if key == ord('r') or key == ord('w'):\n",
    "                new_state = chr(key)\n",
    "                if new_state != recording_state:\n",
    "                    sequences[new_state] += 1  # Update the specific sequence counter\n",
    "                    recording_state = new_state\n",
    "                record = True\n",
    "                accuracy = 1 if key == ord('r') else 0\n",
    "            elif key == ord('s'):\n",
    "                record = False\n",
    "                recording_state = None\n",
    "            elif key == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "df = pd.read_csv('coordinates_2.csv', header=None)\n",
    "df.loc[df[1].notna(), 0] = 'movement_2'\n",
    "df.to_csv('coordinates_2.csv', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Join all the CSVs of the different movements\n",
    "df1 = pd.read_csv('coordinates_1.csv', header=None)\n",
    "df2 = pd.read_csv('coordinates_2.csv', header=None)\n",
    "\n",
    "combined_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "combined_path = 'combined_coordinates.csv'\n",
    "combined_df.to_csv(combined_path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Delete not important data\n",
    "data = pd.read_csv('combined_coordinates.csv')\n",
    "\n",
    "# Identify columns to remove: include specific ranges and all visibility points\n",
    "columns_to_remove_1 = [f\"pose_{c}{i}\" for c in ['x', 'y', 'z', 'v'] for i in range(0, 11)]\n",
    "columns_to_remove_2 = [f\"pose_{c}{i}\" for c in ['x', 'y', 'z', 'v'] for i in range(23, 33)]\n",
    "visibility_columns_pose = [col for col in data.columns if 'pose_v' in col]\n",
    "visibility_columns_left_hand = [col for col in data.columns if 'left_hand_v' in col]\n",
    "visibility_columns_right_hand = [col for col in data.columns if 'right_hand_v' in col]\n",
    "\n",
    "# Combine all columns to remove\n",
    "columns_to_remove = columns_to_remove_1 + columns_to_remove_2 + visibility_columns_pose + visibility_columns_left_hand + visibility_columns_right_hand\n",
    "columns_to_remove = [col for col in columns_to_remove if col in data.columns]\n",
    "\n",
    "# Drop the selected columns from the dataframe\n",
    "data_filtered = data.drop(columns=columns_to_remove)\n",
    "\n",
    "# Round the values and save the filtered data\n",
    "data_filtered = data_filtered.round(3)\n",
    "data_filtered.to_csv('filtered_coordinates.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the filtered dataset\n",
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Create folders in directory\n",
    "data = pd.read_csv('filtered_coordinates.csv')\n",
    "\n",
    "base_dir = 'DataBase'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "unique_classes = data['class'].unique()\n",
    "\n",
    "for class_value in unique_classes:\n",
    "    class_dir = os.path.join(base_dir, str(class_value))\n",
    "    if not os.path.exists(class_dir):\n",
    "        os.makedirs(class_dir)\n",
    "    \n",
    "    class_data = data[data['class'] == class_value]\n",
    "\n",
    "    for accuracy_type, subfolder_name in zip([1, 0], ['R', 'W']):\n",
    "        accuracy_dir = os.path.join(class_dir, subfolder_name)\n",
    "        if not os.path.exists(accuracy_dir):\n",
    "            os.makedirs(accuracy_dir)\n",
    "        \n",
    "        accuracy_data = class_data[class_data['accuracy'] == accuracy_type]\n",
    "        \n",
    "        unique_sequences = accuracy_data['sequence'].unique()\n",
    "        \n",
    "        for sequence in unique_sequences:\n",
    "            sequence_dir = os.path.join(accuracy_dir, str(sequence))\n",
    "            if not os.path.exists(sequence_dir):\n",
    "                os.makedirs(sequence_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosas\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Save individual np arrays\n",
    "data = pd.read_csv('filtered_coordinates.csv')\n",
    "base_dir = 'DataBase'\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "for class_value in data['class'].unique():\n",
    "    class_dir = os.path.join(base_dir, str(class_value))\n",
    "    class_data = data[data['class'] == class_value]\n",
    "\n",
    "    for accuracy_type, subfolder_name in zip([1, 0], ['R', 'W']):\n",
    "        accuracy_dir = os.path.join(class_dir, subfolder_name)\n",
    "        accuracy_data = class_data[class_data['accuracy'] == accuracy_type]\n",
    "\n",
    "        for sequence in accuracy_data['sequence'].unique():\n",
    "            sequence_dir = os.path.join(accuracy_dir, str(sequence))\n",
    "            sequence_data = accuracy_data[accuracy_data['sequence'] == sequence]\n",
    "\n",
    "            sequence_data = sequence_data.reset_index(drop=True)\n",
    "\n",
    "            for index, row in sequence_data.iterrows():\n",
    "                frame_path = os.path.join(sequence_dir, f'{index}.npy')\n",
    "                np.save(frame_path, row.values[3:])\n",
    "\n",
    "print(\"cosas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.354, 0.46, -0.585, 0.157, 0.573, -0.57, 0.497, 0.502, -0.585,\n",
       "       0.178, 0.715, -0.45, 0.448, 0.331, -0.585, 0.209, 0.597, -0.32,\n",
       "       0.446, 0.27, -0.576, 0.205, 0.569, -0.301, 0.425, 0.237, -0.575,\n",
       "       0.217, 0.557, -0.29, 0.425, 0.269, -0.579, 0.226, 0.568, -0.308,\n",
       "       0.483, 0.289, -0.0, 0.485, 0.245, -0.007, 0.481, 0.198, -0.019,\n",
       "       0.466, 0.159, -0.03, 0.451, 0.133, -0.043, 0.494, 0.139, -0.046,\n",
       "       0.43, 0.141, -0.061, 0.397, 0.176, -0.062, 0.377, 0.208, -0.062,\n",
       "       0.485, 0.146, -0.05, 0.418, 0.172, -0.067, 0.39, 0.213, -0.07,\n",
       "       0.371, 0.242, -0.073, 0.472, 0.164, -0.051, 0.412, 0.188, -0.067,\n",
       "       0.39, 0.227, -0.068, 0.376, 0.254, -0.068, 0.459, 0.188, -0.052,\n",
       "       0.413, 0.198, -0.068, 0.393, 0.226, -0.071, 0.379, 0.244, -0.071,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 12: Test if array is in the correct way\n",
    "np.load('DataBase/movement_1/W/0/0.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array=np.load('DataBase/movement_1/W/0/0.npy', allow_pickle=True)\n",
    "len(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Cell 13: Install new libraries for processing and training\n",
    "!pip install tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Import new libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Joining and labeling arrays\n",
    "base_dir = 'DataBase'\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for class_name in os.listdir(base_dir):\n",
    "    class_dir = os.path.join(base_dir, class_name)\n",
    "    for accuracy_type in ['R', 'W']:\n",
    "        accuracy_dir = os.path.join(class_dir, accuracy_type)\n",
    "        for sequence in os.listdir(accuracy_dir):\n",
    "            sequence_dir = os.path.join(accuracy_dir, sequence)\n",
    "            sequence_features = []\n",
    "            for file_name in os.listdir(sequence_dir):\n",
    "                file_path = os.path.join(sequence_dir, file_name)\n",
    "                data = np.load(file_path, allow_pickle=True)\n",
    "                sequence_features.append(data)\n",
    "            features.append(sequence_features)\n",
    "            labels.append(f\"{class_name}_{accuracy_type}\")\n",
    "\n",
    "features_padded = pad_sequences(features, padding='post', dtype='float32')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 18, 162)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 16: Labels test (features_padded and labels_encoded) outputs expected in .shape f_p(x, y, z) / l_e(x, )\n",
    "np.array(features_padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels_encoded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 18, 162)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels_encoded).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window=[]\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frase_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=2000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions[np.argmax(res[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions[np.argmax(y_test[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('crafts.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).toolist()\n",
    "yhat = np.argmax(y_hat, axis=1).toolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real time predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose, \\\n",
    "        mp.solutions.hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            ret, image = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Unable to read frame from video capture\")\n",
    "                break\n",
    "\n",
    "            # Flip image to simulate mirror view\n",
    "            image = cv2.flip(image, 1)\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make detections\n",
    "            pose_results = pose.process(image)\n",
    "            hand_results = hands.process(image)\n",
    "\n",
    "            # RGB 2 BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Draw points\n",
    "            if pose_results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    pose_results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2),\n",
    "                )\n",
    "\n",
    "            if hand_results.multi_hand_landmarks:\n",
    "                for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image,\n",
    "                        hand_landmarks,\n",
    "                        mp.solutions.hands.HAND_CONNECTIONS,\n",
    "                        mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                        mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2),\n",
    "                    )\n",
    "\n",
    "            cv2.imshow(\"Raw Webcam Feed\", image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mynewv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
